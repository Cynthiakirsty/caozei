import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from io import BytesIO
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

st.set_page_config(page_title="æ¯æ—¥æŒ‡æ ‡ + ç›ˆä½™ç‡æ™ºèƒ½é¢„æµ‹", layout="wide")
st.title("æ›¹è´¼ç‰ˆæ¯æ—¥æŒ‡æ ‡åˆ†æä¸ç›ˆä½™ç‡é¢„æµ‹æ¨¡å‹")

# =========================
# å¤šæ–‡ä»¶ä¸Šä¼  + åˆå¹¶
# =========================
uploaded_files = st.file_uploader(
    "ä¸Šä¼ æ¯æ—¥æŒ‡æ ‡æ–‡ä»¶ï¼ˆå¯å¤šé€‰ Excel/CSVï¼‰", 
    type=["xlsx", "xls", "csv"], 
    accept_multiple_files=True
)

if not uploaded_files:
    st.info("ğŸ‘† è¯·ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªåŒ…å«å†å²æ¯æ—¥æŒ‡æ ‡çš„æ–‡ä»¶ã€‚")
    st.stop()

dfs = []
for uploaded_file in uploaded_files:
    fname = uploaded_file.name.lower()
    try:
        if fname.endswith(".csv"):
            df_temp = pd.read_csv(uploaded_file)
        else:
            df_temp = pd.read_excel(uploaded_file)
        
        # æ¸…ç†åˆ—å
        df_temp.columns = df_temp.columns.str.strip().str.replace("\n", "").str.replace(" ", "")
        
        # å°†æ¯ä¸ªæ–‡ä»¶çš„æ•°æ®æ·»åŠ åˆ°dfsåˆ—è¡¨ä¸­
        dfs.append(df_temp)
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶ {uploaded_file.name} å¤±è´¥ï¼š{e}")
        st.stop()

# åˆå¹¶æ‰€æœ‰æ•°æ®å¹¶å»é‡åˆ—
df = pd.concat(dfs, axis=0, ignore_index=True)
df = df.loc[:, ~df.columns.duplicated()]  # å»é‡åˆ—å
df.columns = df.columns.str.strip().str.replace("\n", "").str.replace(" ", "")  # å†æ¬¡æ¸…ç†åˆ—å

st.success("âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸå¹¶å·²åˆå¹¶ï¼")
st.subheader("ğŸ“Š æ•°æ®é¢„è§ˆ")
st.dataframe(df.head(10))

# =========================
# åŸºç¡€å­—æ®µæ ¡éªŒä¸æ¸…æ´—
# =========================
if "æ—¥æœŸ" not in df.columns:
    st.error("âŒ æ–‡ä»¶å¿…é¡»åŒ…å«ã€æ—¥æœŸã€‘åˆ—ã€‚")
    st.stop()

try:
    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
except Exception:
    st.error("æ—¥æœŸæ ¼å¼æ— æ³•è§£æï¼Œè¯·ç¡®ä¿ã€æ—¥æœŸã€‘åˆ—ä¸ºå¯è¯†åˆ«æ ¼å¼ï¼ˆä¾‹å¦‚ YYYY-MM-DDï¼‰ã€‚")
    st.stop()

# æ‰“å°åˆ—åæŸ¥çœ‹
st.write(f"æ•°æ®çš„åˆ—åï¼š{df.columns.tolist()}")

# æ£€æŸ¥â€œæ–°å¢äººæ•°â€ï¼Œâ€œé¦–å……äººæ•°â€ï¼Œâ€œé¦–å……æ¬¡ç•™â€åˆ—æ˜¯å¦å­˜åœ¨
required_cols = ["æ–°å¢äººæ•°", "é¦–å……äººæ•°", "é¦–å……æ¬¡ç•™"]

missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    st.warning(f"âš ï¸ æ•°æ®ä¸­ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_cols}ï¼Œæ— æ³•ç»˜åˆ¶æ¼æ–—å›¾ã€‚")
else:
    # è®¡ç®—æ¬¡æ—¥ç™»å½•äººæ•°
    df["æ¬¡æ—¥ç™»å½•äººæ•°"] = (df["é¦–å……äººæ•°"] * df["é¦–å……æ¬¡ç•™"]).round().astype(int)


    # æ—¥æœŸé€‰æ‹©
    min_date, max_date = df["æ—¥æœŸ"].min(), df["æ—¥æœŸ"].max()
    date_range = st.date_input(
        "é€‰æ‹©æ—¥æœŸèŒƒå›´ï¼ˆé»˜è®¤å±•ç¤ºå…¨éƒ¨ï¼‰",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )

    # ç­›é€‰
    mask = (df["æ—¥æœŸ"] >= pd.to_datetime(date_range[0])) & (df["æ—¥æœŸ"] <= pd.to_datetime(date_range[1]))
    df_filtered = df.loc[mask]

    # æ±‡æ€»
    funnel_data = pd.DataFrame({
        "é˜¶æ®µ": ["æ–°å¢äººæ•°", "é¦–å……äººæ•°", "æ¬¡æ—¥ç™»å½•äººæ•°"],
        "äººæ•°": [
            df_filtered["æ–°å¢äººæ•°"].sum(),
            df_filtered["é¦–å……äººæ•°"].sum(),
            df_filtered["æ¬¡æ—¥ç™»å½•äººæ•°"].sum()
        ]
    })

    # è½¬åŒ–ç‡æ ‡æ³¨
    add_rate = df_filtered["é¦–å……äººæ•°"].sum() / df_filtered["æ–°å¢äººæ•°"].sum() if df_filtered["æ–°å¢äººæ•°"].sum() > 0 else 0
    next_rate = df_filtered["æ¬¡æ—¥ç™»å½•äººæ•°"].sum() / df_filtered["é¦–å……äººæ•°"].sum() if df_filtered["é¦–å……äººæ•°"].sum() > 0 else 0

    st.markdown(f"""
    **è½¬åŒ–ç‡åˆ†æï¼š**
    - æ–°å¢ â†’ é¦–å……ï¼š{add_rate:.2%}  
    - é¦–å…… â†’ æ¬¡æ—¥ç™»å½•ï¼š{next_rate:.2%}
    """)

    # æ¼æ–—å›¾
    fig_funnel = px.funnel(
        funnel_data,
        x="äººæ•°",
        y="é˜¶æ®µ",
        title=f"ç”¨æˆ·è½¬åŒ–æ¼æ–—å›¾ï¼ˆ{date_range[0]} è‡³ {date_range[1]}ï¼‰"
    )
    st.plotly_chart(fig_funnel, use_container_width=True)

# =========================
# åŸæœ‰è¶‹åŠ¿å›¾ï¼ˆä¿ç•™ + æ‰©å±•ï¼‰
# =========================
st.header("ğŸ“ˆ æŒ‡æ ‡è¶‹åŠ¿å›¾")

# ç›ˆä½™ç‡è¶‹åŠ¿
if "ç›ˆä½™ç‡" in df.columns:
    fig2 = px.line(df, x="æ—¥æœŸ", y="ç›ˆä½™ç‡", markers=True, title="ç›ˆä½™ç‡è¶‹åŠ¿")
    st.plotly_chart(fig2, use_container_width=True)

# å……å€¼ vs æç°è¶‹åŠ¿
if all(col in df.columns for col in ["å……å€¼é‡‘é¢", "æç°é‡‘é¢"]):
    fig3 = px.line(df, x="æ—¥æœŸ", y=["å……å€¼é‡‘é¢", "æç°é‡‘é¢"], markers=True, title="å……å€¼é‡‘é¢ & æç°é‡‘é¢è¶‹åŠ¿")
    st.plotly_chart(fig3, use_container_width=True)

# å…¶ä»–å­—æ®µè¶‹åŠ¿å›¾ï¼ˆæ–°å¢ï¼‰
numeric_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in ["ç›ˆä½™ç‡"]]
sel_fields = st.multiselect(
    "é€‰æ‹©è¦é¢å¤–å±•ç¤ºè¶‹åŠ¿çš„å­—æ®µï¼ˆå¯å¤šé€‰ï¼‰",
    numeric_cols,
    default=[c for c in ["å……å€¼äººæ•°", "æç°äººæ•°", "æ—¥æ´»è·ƒç©å®¶æ•°", "æ–°å¢ç”¨æˆ·æ•°"] if c in numeric_cols],
)
for col in sel_fields:
    fig = px.line(df, x="æ—¥æœŸ", y=col, markers=True, title=f"{col} è¶‹åŠ¿")
    st.plotly_chart(fig, use_container_width=True)

# =========================
# ç›ˆä½™ç‡é¢„æµ‹æ¨¡å—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
# =========================
st.header("ğŸ”® ç›ˆä½™ç‡é¢„æµ‹æ¨¡å‹")

all_numeric = df.select_dtypes(include=[np.number]).columns.tolist()
features_candidates = [c for c in all_numeric if c not in ["å……å€¼é‡‘é¢", "æç°é‡‘é¢", "ç›ˆä½™ç‡"]]

selected_features = st.multiselect(
    "é€‰æ‹©ç”¨äºé¢„æµ‹å……å€¼/æç°çš„ç‰¹å¾", features_candidates,
    default=[c for c in ["æ—¥æ´»è·ƒç©å®¶æ•°", "æ–°å¢ç”¨æˆ·æ•°", "æ•´ä½“ARPPU"] if c in features_candidates]
)

if len(selected_features) < 1:
    st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªç‰¹å¾ä»¥ç»§ç»­é¢„æµ‹ã€‚")
    st.stop()

col_a, col_b, col_c = st.columns(3)
with col_a:
    future_days = st.number_input("é¢„æµ‹æœªæ¥å¤©æ•°", min_value=1, max_value=90, value=14)
with col_b:
    model_choice = st.selectbox("é€‰æ‹©æ¨¡å‹", ["LinearRegression", "RandomForestRegressor"])
with col_c:
    use_scenario = st.checkbox("ä½¿ç”¨æƒ…æ™¯å¢é•¿ç‡", value=True)

if use_scenario:
    col1, col2, col3 = st.columns(3)
    with col1:
        rech_daily_pct = st.number_input("å……å€¼æ¯æ—¥å¢é•¿ç‡ %", value=1.0, step=0.1)
    with col2:
        wd_daily_pct = st.number_input("æç°æ¯æ—¥å¢é•¿ç‡ %", value=0.5, step=0.1)
    with col3:
        add_noise_pct = st.slider("æ¯æ—¥æ³¢åŠ¨ Â±%", 0.0, 10.0, 2.0, step=0.1)
else:
    col1, col2 = st.columns(2)
    with col1:
        noise_pct = st.slider("æ¨¡å‹å¤–æ¨éšæœºæ³¢åŠ¨ Â±%", 0.0, 10.0, 2.0, step=0.1)
    with col2:
        recent_window = st.number_input("è¶‹åŠ¿çª—å£å¤©æ•°", min_value=3, max_value=30, value=7)

# è®­ç»ƒæ•°æ®å‡†å¤‡
df_train = df.dropna(subset=selected_features + ["å……å€¼é‡‘é¢", "æç°é‡‘é¢"]).copy()
X = df_train[selected_features].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

if model_choice == "LinearRegression":
    model_rech = LinearRegression().fit(X_scaled, df_train["å……å€¼é‡‘é¢"])
    model_wd = LinearRegression().fit(X_scaled, df_train["æç°é‡‘é¢"])
else:
    from sklearn.ensemble import RandomForestRegressor
    model_rech = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_scaled, df_train["å……å€¼é‡‘é¢"])
    model_wd = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_scaled, df_train["æç°é‡‘é¢"])

# ç”Ÿæˆæœªæ¥æ—¥æœŸå¹¶é¢„æµ‹
last_date = df["æ—¥æœŸ"].max()
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=future_days, freq="D")
future_rows = []

recharge_base = df_train["å……å€¼é‡‘é¢"].iloc[-1] if len(df_train) > 0 else 1.0
withdraw_base = df_train["æç°é‡‘é¢"].iloc[-1] if len(df_train) > 0 else 0.0

for i, d in enumerate(future_dates, start=1):
    if use_scenario:
        pred_rech = recharge_base * ((1 + rech_daily_pct / 100) ** i)
        pred_wd = withdraw_base * ((1 + wd_daily_pct / 100) ** i)
        noise_r = np.random.normal(0, add_noise_pct / 100)
        noise_w = np.random.normal(0, add_noise_pct / 100)
        pred_rech = max(1.0, pred_rech * (1 + noise_r))
        pred_wd = max(0.0, pred_wd * (1 + noise_w))
    else:
        base_feat = df_train[selected_features].iloc[-1]
        daily_delta = (df_train[selected_features].iloc[-1] - df_train[selected_features].iloc[-recent_window]) / recent_window
        day_feat = base_feat + daily_delta * i
        noise = np.random.normal(0, noise_pct / 100, size=day_feat.shape[0])
        day_feat = day_feat * (1 + noise)
        day_feat_scaled = scaler.transform([day_feat])
        pred_rech = float(model_rech.predict(day_feat_scaled)[0])
        pred_wd = float(model_wd.predict(day_feat_scaled)[0])
        if pred_rech <= 0: pred_rech = recharge_base

    pred_rate = (pred_rech - pred_wd) / pred_rech if pred_rech != 0 else 0
    future_rows.append({"æ—¥æœŸ": d, "é¢„æµ‹å……å€¼é‡‘é¢": pred_rech, "é¢„æµ‹æç°é‡‘é¢": pred_wd, "é¢„æµ‹ç›ˆä½™ç‡": pred_rate})

future_df = pd.DataFrame(future_rows)

# å±•ç¤ºç»“æœ
st.subheader("ğŸ“… æœªæ¥æ¯æ—¥é¢„æµ‹ç»“æœ")
st.dataframe(future_df)

# ç»˜åˆ¶å†å²+é¢„æµ‹ç›ˆä½™ç‡
hist = df[["æ—¥æœŸ", "ç›ˆä½™ç‡"]].rename(columns={"ç›ˆä½™ç‡": "å®é™…ç›ˆä½™ç‡"}).set_index("æ—¥æœŸ")
fut = future_df.set_index("æ—¥æœŸ")[["é¢„æµ‹ç›ˆä½™ç‡"]]
comb = pd.concat([hist, fut], axis=0).reset_index()
fig_pred = px.line(comb, x="æ—¥æœŸ", y=["å®é™…ç›ˆä½™ç‡", "é¢„æµ‹ç›ˆä½™ç‡"], title="å®é™… vs é¢„æµ‹ç›ˆä½™ç‡", markers=True)
st.plotly_chart(fig_pred, use_container_width=True)

# ä¸‹è½½
output = BytesIO()
with pd.ExcelWriter(output, engine="openpyxl") as writer:
    future_df.to_excel(writer, index=False, sheet_name="é¢„æµ‹ç»“æœ")
st.download_button(
    "ğŸ’¾ ä¸‹è½½é¢„æµ‹ç»“æœï¼ˆExcelï¼‰",
    data=output.getvalue(),
    file_name="future_profit_predictions.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

# ç›¸å…³æ€§å±•ç¤º
st.header("ğŸ“Œ å½±å“ç›ˆä½™ç‡çš„å…³é”®ç‰¹å¾")
if "ç›ˆä½™ç‡" in df.columns:
    corr_with_target = df[selected_features + ["ç›ˆä½™ç‡"]].corr()["ç›ˆä½™ç‡"].drop("ç›ˆä½™ç‡").sort_values(ascending=False)
    st.dataframe(corr_with_target.to_frame("ç›¸å…³ç³»æ•°"))

try:
    coef_df = pd.DataFrame({
        "ç‰¹å¾": selected_features,
        "å……å€¼æ¨¡å‹ç³»æ•°": getattr(model_rech, "coef_", [np.nan]*len(selected_features)),
        "æç°æ¨¡å‹ç³»æ•°": getattr(model_wd, "coef_", [np.nan]*len(selected_features)),
    }).set_index("ç‰¹å¾")
    st.subheader("æ¨¡å‹ç³»æ•°ï¼ˆä»…çº¿æ€§æ¨¡å‹æ—¶æœ‰æ•ˆï¼‰")
    st.dataframe(coef_df)
except Exception:
    pass

# ===== è¡¥å……è¯´æ˜ =====
st.markdown("""
---
ğŸ” **è¯´æ˜å°ç»“ï¼š**

ä½ å¯é€‰æ‹©ã€Œæƒ…æ™¯æ³•ã€ï¼ˆæ‰‹åŠ¨è®¾å®šå¢é•¿ç‡ï¼‰æˆ–ã€Œæ¨¡å‹æ³•ã€ï¼ˆåŸºäºæ‰€é€‰ç‰¹å¾ç”±å›å½’å™¨é¢„æµ‹å……å€¼/æç°å¹¶å¤–æ¨ï¼‰ã€‚  
è‹¥éœ€è¦æ›´ç¨³å¥çš„éçº¿æ€§é¢„æµ‹ï¼ˆæ¨èï¼‰ï¼Œå¯åˆ‡æ¢åˆ° **RandomForestRegressor** å¹¶è°ƒå‚ï¼›  
åŒæ—¶å¯åŠ å…¥ã€Œå‘æ”¾å æ¯”ã€ä¸ã€ŒRTPã€ç­‰å› ç´ ï¼Œå®ƒä»¬ä¼šæ˜¾è‘—å½±å“ç›ˆä½™ç‡å˜åŒ–ã€‚
""")