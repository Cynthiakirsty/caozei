import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.figure_factory as ff
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from io import BytesIO

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ¯æ—¥æŒ‡æ ‡ + ç›ˆä½™ç‡æ™ºèƒ½é¢„æµ‹ï¼ˆä¿ç•™åŸå›¾è¡¨ï¼‰", layout="wide")
st.title("æ›¹è´¼ç‰ˆæ¯æ—¥æŒ‡æ ‡åˆ†æä¸æŒ‰å……æé¢„æµ‹çš„ç›ˆä½™ç‡æ¨¡å‹")

# =========================
# ä¸Šä¼ ä¸è¯»å–ï¼ˆä¿ç•™åŸæ ·ï¼‰
# =========================
uploaded_file = st.file_uploader("ä¸Šä¼ æ¯æ—¥æŒ‡æ ‡æ–‡ä»¶ï¼ˆExcel/CSVï¼‰", type=["xlsx", "xls", "csv"])

if not uploaded_file:
    st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ åŒ…å«å†å²æ¯æ—¥æŒ‡æ ‡çš„æ–‡ä»¶ï¼ˆè‡³å°‘åŒ…å«ï¼šæ—¥æœŸã€å……å€¼é‡‘é¢ã€æç°é‡‘é¢ï¼‰ã€‚")
    st.stop()

try:
    fname = uploaded_file.name.lower()
    if fname.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
    else:
        df = pd.read_excel(uploaded_file)
except Exception as e:
    st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{e}")
    st.stop()

# æ¸…ç†ä¸æ ‡å‡†åŒ–ï¼ˆä¿ç•™åŸæ ·ï¼‰
df.columns = df.columns.str.strip()
st.success("âœ… æ•°æ®è¯»å–æˆåŠŸï¼")
st.subheader("ğŸ“… æ•°æ®é¢„è§ˆ")
st.dataframe(df.head(10))

# å¿…è¦åˆ—æ£€æŸ¥
expected_cols = ["æ—¥æœŸ", "æ–°å¢äººæ•°", "æ—¥æ´»è·ƒäººæ•°", "ç›ˆä½™ç‡", "å……å€¼äººæ•°", "å……å€¼é‡‘é¢", "æç°äººæ•°", "æç°é‡‘é¢", "é¦–å……æ¬¡ç•™", "é¦–å……3ç•™", "æ–°ARPPU", "è€ARPPU"]
missing = [c for c in expected_cols if c not in df.columns]
if missing:
    st.warning(f"âš ï¸ æ³¨æ„ï¼šæ–‡ä»¶ä¸­ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼ˆéƒ¨åˆ†åŠŸèƒ½å—é™ï¼‰ï¼š{missing}")

# æ ¼å¼åŒ–æ—¥æœŸä¸æ•°å€¼ï¼ˆä¿ç•™åŸæ ·ï¼‰
if "æ—¥æœŸ" in df.columns:
    try:
        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
    except Exception:
        st.error("æ—¥æœŸæ ¼å¼æ— æ³•è§£æï¼Œè¯·ç¡®ä¿ã€æ—¥æœŸã€‘åˆ—ä¸ºå¯è¯†åˆ«æ ¼å¼ï¼ˆä¾‹å¦‚ YYYY-MM-DDï¼‰ã€‚")
        st.stop()
else:
    st.error("æ–‡ä»¶å¿…é¡»åŒ…å«ã€æ—¥æœŸã€‘åˆ—ã€‚")
    st.stop()

# è®¡ç®—æˆ–æ ‡å‡†åŒ–éƒ¨åˆ†åˆ—ï¼ˆä¿ç•™åŸæ ·ï¼‰
if "å……å€¼é‡‘é¢" in df.columns and "å……å€¼äººæ•°" in df.columns:
    df["æ•´ä½“ARPPU"] = df["å……å€¼é‡‘é¢"] / df["å……å€¼äººæ•°"].replace(0, np.nan)
else:
    df["æ•´ä½“ARPPU"] = np.nan

# å¦‚æœç›ˆä½™ç‡æ²¡æœ‰ä½†æœ‰å……æåˆ™è®¡ç®—
if "ç›ˆä½™ç‡" not in df.columns and "å……å€¼é‡‘é¢" in df.columns and "æç°é‡‘é¢" in df.columns:
    df["ç›ˆä½™ç‡"] = (df["å……å€¼é‡‘é¢"] - df["æç°é‡‘é¢"]) / df["å……å€¼é‡‘é¢"]
    df["ç›ˆä½™ç‡"] = df["ç›ˆä½™ç‡"].replace([np.inf, -np.inf], np.nan).fillna(0)

# =========================
# åŸæœ‰å›¾è¡¨ï¼ˆä¿æŒå¹¶å±•ç¤ºï¼‰
# =========================
st.header("ğŸ“ˆ åŸæœ‰æŒ‡æ ‡è¶‹åŠ¿")

# æ–°å¢ & æ—¥æ´»
if all(col in df.columns for col in ["æ–°å¢äººæ•°", "æ—¥æ´»è·ƒäººæ•°"]):
    fig1 = px.line(df, x="æ—¥æœŸ", y=["æ–°å¢äººæ•°", "æ—¥æ´»è·ƒäººæ•°"], markers=True, title="æ–°å¢äººæ•° & æ—¥æ´»è¶‹åŠ¿")
    st.plotly_chart(fig1, use_container_width=True)

# ç›ˆä½™ç‡è¶‹åŠ¿
if "ç›ˆä½™ç‡" in df.columns:
    fig2 = px.line(df, x="æ—¥æœŸ", y="ç›ˆä½™ç‡", markers=True, title="ç›ˆä½™ç‡è¶‹åŠ¿")
    st.plotly_chart(fig2, use_container_width=True)

# å……å€¼ vs æç°
if all(col in df.columns for col in ["å……å€¼é‡‘é¢", "æç°é‡‘é¢"]):
    fig3 = px.line(df, x="æ—¥æœŸ", y=["å……å€¼é‡‘é¢", "æç°é‡‘é¢"], markers=True, title="å……å€¼é‡‘é¢ & æç°é‡‘é¢è¶‹åŠ¿")
    st.plotly_chart(fig3, use_container_width=True)

# ARPPU å›¾
arppu_cols = [c for c in ["æ–°ARPPU", "è€ARPPU", "æ•´ä½“ARPPU"] if c in df.columns]
if arppu_cols:
    fig4 = px.line(df, x="æ—¥æœŸ", y=arppu_cols, markers=True, title="ARPPU è¶‹åŠ¿å¯¹æ¯”")
    st.plotly_chart(fig4, use_container_width=True)

# ç›¸å…³æ€§çƒ­åŠ›å›¾ä¸ç‰¹å¾é‡è¦æ€§ï¼ˆä¿ç•™åŸæ ·ï¼‰
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
# å¦‚æœåŒ…å«ç›®æ ‡åˆ—åˆ™æ˜¾ç¤ºçƒ­åŠ›å›¾
if "ç›ˆä½™ç‡" in df.columns and len(numeric_cols) >= 2:
    st.subheader("ğŸ”¥ ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾")
    corr = df[numeric_cols].corr()
    heatmap = ff.create_annotated_heatmap(
        z=np.round(corr.values, 2),
        x=list(corr.columns),
        y=list(corr.index),
        annotation_text=np.round(corr.values, 2),
        showscale=True,
        colorscale="RdBu",
        reversescale=True
    )
    heatmap.update_layout(title="ç›¸å…³æ€§çŸ©é˜µï¼ˆæ•°å€¼åˆ—ï¼‰", width=900, height=700)
    st.plotly_chart(heatmap, use_container_width=True)

# å¦‚æœä½ ä¹‹å‰æœ‰ç‰¹å¾é‡è¦æ€§å±•ç¤ºï¼Œè¿™é‡Œä¹Ÿä¿ç•™ç±»ä¼¼å±•ç¤ºï¼ˆå½“æ¨¡å‹å¯å»ºæ—¶ï¼‰
# =========================
# æ–°å¢æ¨¡å—ï¼šæŒ‰å……å€¼/æç°åˆ†åˆ«å»ºæ¨¡ï¼Œå†æŒ‰å…¬å¼è®¡ç®—æœªæ¥æ¯æ—¥ç›ˆä½™ç‡ï¼ˆ**ä»…æ–°å¢**ï¼‰
# =========================
st.header("ğŸ”® æŒ‰å……å€¼/æç°é¢„æµ‹æœªæ¥æ¯æ—¥ç›ˆä½™ç‡")
st.markdown("è¯´æ˜ï¼šå…ˆåˆ†åˆ«é¢„æµ‹æœªæ¥æ¯æ—¥çš„ **å……å€¼é‡‘é¢** ä¸ **æç°é‡‘é¢**ï¼Œå†æŒ‰å…¬å¼ `(å……å€¼-æç°)/å……å€¼` è®¡ç®—æ¯æ—¥ç›ˆä½™ç‡ã€‚ä½ å¯ä»¥é€‰æ‹©å›å½’æ¨¡å‹æˆ–æƒ…æ™¯å¢é•¿ç‡ã€‚")

# é€‰æ‹©ç”¨äºé¢„æµ‹çš„ç‰¹å¾ï¼ˆæ’é™¤å……å€¼/æç°è‡ªèº«ï¼‰
all_numeric = df.select_dtypes(include=[np.number]).columns.tolist()
features_candidates = [c for c in all_numeric if c not in ["å……å€¼é‡‘é¢", "æç°é‡‘é¢", "ç›ˆä½™ç‡"]]
selected_features = st.multiselect("é€‰æ‹©ç”¨äºé¢„æµ‹å……å€¼/æç°çš„ç‰¹å¾ï¼ˆè‡³å°‘1ä¸ªï¼‰", features_candidates,
                                   default=[c for c in ["æ—¥æ´»è·ƒäººæ•°", "æ–°å¢äººæ•°", "æ•´ä½“ARPPU"] if c in features_candidates])

if len(selected_features) < 1:
    st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªç‰¹å¾ä»¥ç»§ç»­é¢„æµ‹ã€‚")
    st.stop()

# é¢„æµ‹å‚æ•°ï¼šå¤©æ•°ã€æ¨¡å‹ç±»å‹ã€æƒ…æ™¯å¼€å…³
col_a, col_b, col_c = st.columns([2,2,2])
with col_a:
    future_days = st.number_input("é¢„æµ‹æœªæ¥å¤©æ•° (å¤©)", min_value=1, max_value=90, value=14)
with col_b:
    model_choice = st.selectbox("å›å½’æ¨¡å‹ï¼ˆç”¨äºè®­ç»ƒå……å€¼/æç°ï¼‰", ["LinearRegression", "RandomForestï¼ˆæ›´é²æ£’ï¼‰"])
with col_c:
    use_scenario = st.checkbox("ä½¿ç”¨æƒ…æ™¯ï¼ˆæ‰‹åŠ¨è®¾å®šæ¯æ—¥å¢é•¿ç‡ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨æ¨¡å‹é¢„æµ‹ + å¯é€‰å¤–æ¨", value=True)

# æƒ…æ™¯å‚æ•°ï¼ˆä»…å½“ use_scenario Trueï¼‰
if use_scenario:
    st.markdown("æƒ…æ™¯è®¾ç½®ï¼šæ¯æ—¥å¢é•¿ç‡ä¸ºå¤åˆ©ï¼ˆå¯ä¸ºè´Ÿæ•°ï¼‰ï¼Œä¹Ÿå¯é€‰æ‹©æ˜¯å¦åŠ å…¥éšæœºæ³¢åŠ¨ã€‚")
    col1, col2, col3 = st.columns(3)
    with col1:
        rech_daily_pct = st.number_input("æƒ…æ™¯ï¼šå……å€¼æ¯æ—¥å¢é•¿ç‡ %", value=1.0, step=0.1)
    with col2:
        wd_daily_pct = st.number_input("æƒ…æ™¯ï¼šæç°æ¯æ—¥å¢é•¿ç‡ %", value=0.5, step=0.1)
    with col3:
        add_noise_pct = st.slider("æ¯æ—¥éšæœºæ³¢åŠ¨å¹…åº¦ Â±% (ç”¨äºæƒ…æ™¯æ¨¡æ‹Ÿ)", 0.0, 10.0, 2.0, step=0.1)
else:
    st.markdown("ä¸ä½¿ç”¨æƒ…æ™¯ï¼šå°†åŸºäºæ¨¡å‹é¢„æµ‹å¹¶ç”¨æœ€è¿‘è¶‹åŠ¿å¤–æ¨ï¼ˆå¯å¸¦å°å¹…éšæœºæ‰°åŠ¨ï¼‰ã€‚")
    coln1, coln2 = st.columns(2)
    with coln1:
        noise_pct = st.slider("æ¨¡å‹å¤–æ¨æ¯æ—¥éšæœºæ³¢åŠ¨ Â±%", 0.0, 10.0, 2.0, step=0.1)
    with coln2:
        recent_window = st.number_input("ç”¨äºè®¡ç®—æœ€è¿‘è¶‹åŠ¿çš„çª—å£å¤©æ•°", min_value=3, max_value=30, value=7)

# è®­ç»ƒæ ·æœ¬æ£€æŸ¥
df_train = df.dropna(subset=selected_features + ["å……å€¼é‡‘é¢", "æç°é‡‘é¢"]).copy()
if df_train.shape[0] < max(10, len(selected_features)*5):
    st.warning("å†å²æ ·æœ¬è¾ƒå°‘ï¼Œæ¨¡å‹é¢„æµ‹å¯èƒ½ä¸ç¨³å®šï¼ˆå»ºè®®å¢åŠ æ›´å¤šå†å²æ—¥æœŸæ ·æœ¬ï¼‰ã€‚")

# è®­ç»ƒæ¨¡å‹ï¼ˆä¸¤ä¸ªæ¨¡å‹ï¼šå……å€¼ã€æç°ï¼‰
X = df_train[selected_features].values
scaler_amt = StandardScaler()
X_scaled = scaler_amt.fit_transform(X)

if model_choice == "LinearRegression":
    model_rech = LinearRegression()
    model_wd = LinearRegression()
    model_rech.fit(X_scaled, df_train["å……å€¼é‡‘é¢"].values)
    model_wd.fit(X_scaled, df_train["æç°é‡‘é¢"].values)
else:
    # éšæœºæ£®æ—ï¼ˆéå¿…é¡»ï¼ŒæŒ‰éœ€å®‰è£… sklearnï¼‰
    try:
        from sklearn.ensemble import RandomForestRegressor
        model_rech = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_scaled, df_train["å……å€¼é‡‘é¢"].values)
        model_wd = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_scaled, df_train["æç°é‡‘é¢"].values)
    except Exception as e:
        st.error("RandomForest æœªå®‰è£…æˆ–å‡ºé”™ï¼Œå›é€€ä½¿ç”¨ LinearRegressionã€‚")
        model_rech = LinearRegression().fit(X_scaled, df_train["å……å€¼é‡‘é¢"].values)
        model_wd = LinearRegression().fit(X_scaled, df_train["æç°é‡‘é¢"].values)

# ç”Ÿæˆæœªæ¥æ—¥æœŸä¸åŸºå‡†ç‰¹å¾å¤–æ¨ï¼ˆåŸºäºæœ€è¿‘ N å¤©çº¿æ€§å¢é‡ï¼‰
last_date = df["æ—¥æœŸ"].max()
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=future_days, freq='D')

# è®¡ç®—æœ€è¿‘è¶‹åŠ¿åŸºå‡†
if not use_scenario:
    window = min(len(df_train), recent_window if 'recent_window' in locals() else 7)
    recent = df_train.tail(window).reset_index(drop=True)
    if len(recent) >= 2:
        # æ—¥å‡å¢é‡ï¼ˆç”¨çº¿æ€§å·®ï¼‰
        daily_delta = (recent[selected_features].iloc[-1] - recent[selected_features].iloc[0]) / max(1, len(recent)-1)
    else:
        daily_delta = np.zeros(len(selected_features))
    base_feat = recent[selected_features].iloc[-1] if len(recent) > 0 else df_train[selected_features].iloc[-1]
else:
    # æƒ…æ™¯ä¹Ÿå¯ä»¥åŸºäºæœ€åä¸€å¤©ç‰¹å¾ä¸ºåŸºå‡†ï¼ˆä½†æˆ‘ä»¬ç”¨æƒ…æ™¯å¢é•¿ç›´æ¥å¯¹å……å€¼/æç°é‡‘é¢è®¡ç®—ï¼‰
    if len(df_train) > 0:
        base_feat = df_train[selected_features].iloc[-1]
    else:
        st.error("å†å²æ•°æ®ä¸è¶³ä»¥å¤–æ¨æƒ…æ™¯ã€‚")
        st.stop()

# å¼€å§‹é€æ—¥é¢„æµ‹ï¼ˆä¿æŒåŸå›¾ä¸å˜ï¼Œä»…æ–°å¢ç»“æœåŒºï¼‰
future_rows = []
recharge_base = df_train["å……å€¼é‡‘é¢"].iloc[-1] if len(df_train)>0 else 1.0
withdraw_base = df_train["æç°é‡‘é¢"].iloc[-1] if len(df_train)>0 else 0.0

for i, d in enumerate(future_dates, start=1):
    if use_scenario:
        # 1) ç”¨ç”¨æˆ·æƒ…æ™¯ç›´æ¥æŒ‰å¢é•¿ç‡æ¨å……å€¼ä¸æç°ï¼ˆå¤åˆ©ï¼‰ï¼Œå†åŠ å…¥éšæœºæ³¢åŠ¨
        pred_rech = recharge_base * ((1 + rech_daily_pct/100) ** i)
        pred_wd = withdraw_base * ((1 + wd_daily_pct/100) ** i)
        # åŠ å™ªå£°
        noise_r = np.random.normal(0, add_noise_pct/100)
        noise_w = np.random.normal(0, add_noise_pct/100)
        pred_rech = max(1.0, pred_rech * (1 + noise_r))
        pred_wd = max(0.0, pred_wd * (1 + noise_w))
    else:
        # 2) ç”¨æ¨¡å‹é¢„æµ‹ï¼šå…ˆå¤–æ¨ç‰¹å¾ï¼Œç„¶åæ¨¡å‹é¢„æµ‹å……å€¼/æç°
        day_feat = base_feat + daily_delta * i
        # å¯é€‰å°å¹…éšæœºæ‰°åŠ¨
        noise = np.random.normal(0, noise_pct/100, size=day_feat.shape[0])
        day_feat = day_feat * (1 + noise)
        day_feat_df = pd.DataFrame([day_feat.values], columns=selected_features)
        day_feat_scaled = scaler_amt.transform(day_feat_df.values)
        pred_rech = float(model_rech.predict(day_feat_scaled)[0])
        pred_wd = float(model_wd.predict(day_feat_scaled)[0])
        # é˜²æŠ¤
        if pred_rech <= 0:
            pred_rech = recharge_base * (1 + 0.001*i)
        pred_wd = max(0.0, pred_wd)

    # è®¡ç®—ç›ˆä½™ç‡ï¼ˆæŒ‰å…¬å¼ï¼‰
    if pred_rech == 0:
        pred_rate = 0.0
    else:
        pred_rate = (pred_rech - pred_wd) / pred_rech
        pred_rate = float(np.clip(pred_rate, -1.0, 1.0))

    future_rows.append({
        "æ—¥æœŸ": d,
        "é¢„æµ‹å……å€¼é‡‘é¢": pred_rech,
        "é¢„æµ‹æç°é‡‘é¢": pred_wd,
        "é¢„æµ‹ç›ˆä½™ç‡": pred_rate
    })

future_df = pd.DataFrame(future_rows)

# æ˜¾ç¤ºé¢„æµ‹ç»“æœï¼ˆæ–°å¢ï¼Œä¸åˆ é™¤åŸå›¾ï¼‰
st.subheader("ğŸ“… æœªæ¥é€æ—¥é¢„æµ‹ç»“æœ")
st.dataframe(future_df)

# ç»˜åˆ¶å†å²å®é™…ç›ˆä½™ç‡ä¸é¢„æµ‹ç›ˆä½™ç‡ï¼ˆæ–°å¢ï¼‰
display_hist = df[["æ—¥æœŸ", "ç›ˆä½™ç‡"]].rename(columns={"ç›ˆä½™ç‡": "å®é™…ç›ˆä½™ç‡"}).set_index("æ—¥æœŸ")
display_future = future_df.set_index("æ—¥æœŸ")[["é¢„æµ‹ç›ˆä½™ç‡"]]
display_combined = pd.concat([display_hist, display_future], axis=0).reset_index()
fig_pred = px.line(display_combined, x="æ—¥æœŸ", y=["å®é™…ç›ˆä½™ç‡", "é¢„æµ‹ç›ˆä½™ç‡"],
                   title="å†å²å®é™…ç›ˆä½™ç‡ vs æœªæ¥é¢„æµ‹ç›ˆä½™ç‡", markers=True)
st.plotly_chart(fig_pred, use_container_width=True)

# å…è®¸å¯¼å‡ºé¢„æµ‹ç»“æœï¼ˆæ–°å¢ï¼‰
output = BytesIO()
with pd.ExcelWriter(output, engine="openpyxl") as writer:
    future_df.to_excel(writer, index=False, sheet_name="é¢„æµ‹ç»“æœ")
st.download_button("ğŸ’¾ ä¸‹è½½é¢„æµ‹ç»“æœï¼ˆExcelï¼‰", data=output.getvalue(), file_name="future_profit_predictions.xlsx",
                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# =========================
# ä¿ç•™åŸæœ‰çš„ç‰¹å¾é‡è¦æ€§å±•ç¤ºï¼ˆè‹¥æœ‰æ¨¡å‹ï¼‰
# =========================
st.header("ğŸ“Œ å½±å“ç›ˆä½™ç‡çš„å…³é”®å› ç´ ")
# å¦‚æœåŸå…ˆè®­ç»ƒäº†æ¨¡å‹ï¼ˆæˆ‘ä»¬ä¹‹å‰è®­ç»ƒè¿‡ modelï¼‰ï¼Œå±•ç¤ºç³»æ•°ï¼ˆæ³¨æ„ï¼šåœ¨æ–°å¢æ¨¡å—æˆ‘ä»¬è®­ç»ƒäº† model_rech/model_wdï¼‰
# è‹¥ df ä¸­å­˜åœ¨ selected_featuresï¼Œåˆ™è®¡ç®—ç®€å•ç›¸å…³æ€§ä¸å±•ç¤ºç³»æ•°ï¼ˆå¦‚çº¿æ€§å›å½’çš„ç³»æ•°ä¸å¯ç›´æ¥å¯¹åº”å……æå½±å“ï¼‰
if "ç›ˆä½™ç‡" in df.columns and len(selected_features) > 0:
    corr_with_target = df[selected_features + ["ç›ˆä½™ç‡"]].corr()["ç›ˆä½™ç‡"].drop("ç›ˆä½™ç‡").sort_values(ascending=False)
    st.write("ä¸ç›ˆä½™ç‡ç›¸å…³æ€§ï¼ˆPearsonï¼‰:")
    st.dataframe(corr_with_target.to_frame("ç›¸å…³ç³»æ•°"))

# å¦‚æœä½ æƒ³çœ‹æ¨¡å‹ç³»æ•°ï¼ˆå……å€¼/æç°æ¨¡å‹ï¼‰ï¼Œæˆ‘ä»¬ä¹Ÿå±•ç¤º
try:
    rech_coefs = model_rech.coef_
    wd_coefs = model_wd.coef_
    coef_df = pd.DataFrame({
        "ç‰¹å¾": selected_features,
        "å……å€¼æ¨¡å‹ç³»æ•°": rech_coefs,
        "æç°æ¨¡å‹ç³»æ•°": wd_coefs
    }).set_index("ç‰¹å¾")
    st.subheader("å……å€¼/æç°æ¨¡å‹ç³»æ•°ï¼ˆç”¨äºå‚è€ƒï¼Œéœ€æ ‡å‡†åŒ–åæ›´å¯æ¯”ï¼‰")
    st.dataframe(coef_df)
except Exception:
    pass

st.markdown("""
---
ğŸ” è¯´æ˜å°ç»“ï¼š
- ä½ å¯é€‰æ‹©ã€Œæƒ…æ™¯æ³•ã€ï¼ˆæ‰‹åŠ¨è®¾å®šå¢é•¿ç‡ï¼‰æˆ–ã€Œæ¨¡å‹æ³•ã€ï¼ˆåŸºäºæ‰€é€‰ç‰¹å¾ç”±å›å½’å™¨é¢„æµ‹å……å€¼/æç°å¹¶å¤–æ¨ï¼‰ã€‚  
- è‹¥éœ€è¦æ›´ç¨³å¥çš„éçº¿æ€§é¢„æµ‹ï¼ˆæ¨èï¼‰ï¼Œå¯åˆ‡æ¢åˆ° RandomForest å¹¶è°ƒå‚ï¼›ä¹Ÿå¯å¢åŠ ç½®ä¿¡åŒºé—´ä¸å¤šæƒ…æ™¯å¯¹æ¯”ï¼ˆæˆ‘å¯ä»¥ç»§ç»­åŠ ï¼‰ã€‚  
""")
